# 🛡️ WatchBot: 실시간 감정 인식 기반 보호자 알림 시스템

## 🔍 프로젝트 개요

**WatchBot**은 감정 인식, 음성 처리(STT/TTS), 실시간 영상 분석을 통해  
사용자의 상태를 판단하고, 위험 상황에서 보호자에게 알림을 자동 전달하는  
**AI 기반 스마트 감시 시스템**입니다.

> 주 사용자 대상: 독거노인, 치매 환자, 고위험 감정 상태자 등  
> 실시간 반응형 시스템 + 하드웨어 인터페이스(스피커, 서보 모터 등)

## 🧩 주요 기능

| 기능 | 설명 |
|------|------|
| 얼굴 감정 인식 | YOLOv11 기반 표정 분석 (TensorRT 최적화) |
| 음성 수신 및 인식 | Raspberry Pi에서 마이크로 입력받은 음성 → mp4 → A100 서버 전송 |
| TTS 음성 응답 | 감정 상태/음성 입력에 대한 자연스러운 음성 응답 재생 |
| RTSP 영상 스트리밍 | Pi에서 Jetson으로 실시간 영상 전송 (`libcamera-vid + ffmpeg`) |
| 반응형 영상 출력 | 감정 분석 결과에 따라 지정된 `.mp4` 영상 자동 재생 |
| 보호자 알림 시스템 | 위험 감정 (`angry`, `scared`, `sad`) 발생 시 보호자 알림 트리거 준비중 |

## 🛠️ 시스템 구성

- **Raspberry Pi 5**: 카메라, 마이크, 스피커, 서보 제어
- **Jetson Xavier**: 감정 인식 모델 실행, STT/TTS 연동
- **A100 서버**: 대규모 음성 처리 지원

## 📁 폴더 구조

```
WatchBot/
├── hardware/               # 센서, 서보, 마이크 등 제어 코드
├── software/               # 감정 분석, STT, TTS 등 AI 처리 파이프라인
├── media/                  # 감정 반응 영상 및 예제 음성 파일
├── models/                 # ONNX 및 TensorRT 모델
├── requirements.txt        # Python 의존성 목록
└── README.md               # 프로젝트 설명 파일
```

## 🙋 담당 역할

| 이름 | 담당 역할 |
|------|-----------|
| 오황우 | 전체 하드웨어 설계/연동, Raspberry Pi 모듈 구현, 프로젝트 통합 |
| 공동개발자 | YOLOv11 기반 감정 모델 학습, TensorRT 최적화, STT/TTS 서버 연동 |

## 📜 라이선스

본 프로젝트는 MIT License를 따릅니다.
